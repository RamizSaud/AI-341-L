{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8aea833c",
   "metadata": {},
   "source": [
    "# In the following code:\n",
    "### Q1: Neural Network was created with initialization of weights, it takes 2 inputs, 1 hidden layer with 3 neurons, 1 output\n",
    "### Q2: Forward Propogation was implemented\n",
    "### Q3: Mean absolute error was used as a Loss Function\n",
    "### Q4: Learning rate was set to 1 as I wanted fast convergence due to my small dataset, 50000 epochs were used with batch size equal to 1\n",
    "### Q5: I trained the NN with AND gate dataset\n",
    "### Q6: I printed Weights after every 1000 epochs\n",
    "### Q7: I tested the NN with the AND gate dataset and got very good accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fc1b4768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3609611220365596\n",
      "Weights 1:  [[-0.19191731  0.98514636 -1.36253847]\n",
      " [-0.57258491 -1.14480505  0.37728258]]\n",
      "Weights 2:  [[0.17313571]\n",
      " [0.24598147]\n",
      " [1.04211982]]\n",
      "Loss: 0.06560088477087066\n",
      "Weights 1:  [[-2.79928433  0.67361778 -6.51125806]\n",
      " [-3.07166642 -6.48749192  0.68758551]]\n",
      "Weights 2:  [[-2.51922038]\n",
      " [-4.38397376]\n",
      " [-4.42141615]]\n",
      "Loss: 0.06380526897394621\n",
      "Weights 1:  [[-3.21744439  0.81452377 -7.57934044]\n",
      " [-3.52205289 -7.55973649  0.8219717 ]]\n",
      "Weights 2:  [[-2.39766876]\n",
      " [-4.96833715]\n",
      " [-5.00100065]]\n",
      "Loss: 0.06330894491857282\n",
      "Weights 1:  [[-3.44512213  0.87785874 -8.15458331]\n",
      " [-3.76214427 -8.13837756  0.88250394]]\n",
      "Weights 2:  [[-2.31846256]\n",
      " [-5.2753294 ]\n",
      " [-5.30454348]]\n",
      "Loss: 0.06308154420444577\n",
      "Weights 1:  [[-3.60070674  0.91722201 -8.54685435]\n",
      " [-3.92454758 -8.53300546  0.9202888 ]]\n",
      "Weights 2:  [[-2.25996254]\n",
      " [-5.48199322]\n",
      " [-5.50881552]]\n",
      "Loss: 0.06295218132846404\n",
      "Weights 1:  [[-3.71849606  0.94528478 -8.84381949]\n",
      " [-4.0467351  -8.83169279  0.94733013]]\n",
      "Weights 2:  [[-2.21345766]\n",
      " [-5.63712407]\n",
      " [-5.66217628]]\n",
      "Loss: 0.06286905680133563\n",
      "Weights 1:  [[-3.81307286  0.96687553 -9.08241815]\n",
      " [-4.1444233  -9.07161149  0.96820217]]\n",
      "Weights 2:  [[-2.17476815]\n",
      " [-5.76099335]\n",
      " [-5.78466749]]\n",
      "Loss: 0.06281128703961113\n",
      "Weights 1:  [[-3.8919719   0.98431216 -9.28164982]\n",
      " [-4.22565976 -9.2718928   0.985104  ]]\n",
      "Weights 2:  [[-2.14157864]\n",
      " [-5.86392637]\n",
      " [-5.88648699]]\n",
      "Loss: 0.06276887807191243\n",
      "Weights 1:  [[-3.95958527  0.99887414 -9.45256096]\n",
      " [-4.29510499 -9.44366242  0.99925176]]\n",
      "Weights 2:  [[-2.11247377]\n",
      " [-5.95188222]\n",
      " [-5.97351757]]\n",
      "Loss: 0.06273646063962485\n",
      "Weights 1:  [[-4.0186938   1.01133768 -9.60213462]\n",
      " [-4.35569489 -9.59395395  1.01138469]]\n",
      "Weights 2:  [[-2.08652501]\n",
      " [-6.02860577]\n",
      " [-6.04945547]]\n",
      "Loss: 0.06271089813017468\n",
      "Weights 1:  [[-4.0711677   1.02220699 -9.73506279]\n",
      " [-4.40939612 -9.72749318  1.02198383]]\n",
      "Weights 2:  [[-2.06309007]\n",
      " [-6.09660097]\n",
      " [-6.11677202]]\n",
      "Loss: 0.06269023789259978\n",
      "Weights 1:  [[-4.11832425  1.03182696 -9.85464825]\n",
      " [-4.45758927 -9.84760638  1.03137885]]\n",
      "Weights 2:  [[-2.041706  ]\n",
      " [-6.15762309]\n",
      " [-6.17719966]]\n",
      "Loss: 0.06267320200413383\n",
      "Weights 1:  [[-4.16112567  1.04044336 -9.96330276]\n",
      " [-4.50128004 -9.95672227  1.03980504]]\n",
      "Weights 2:  [[-2.02202791]\n",
      " [-6.21294927]\n",
      " [-6.23199903]]\n",
      "Loss: 0.0626589196532237\n",
      "Weights 1:  [[ -4.20029592   1.04823712 -10.06284063]\n",
      " [ -4.54122329 -10.05666763   1.04743589]]\n",
      "Weights 2:  [[-2.0037919 ]\n",
      " [-6.26353721]\n",
      " [-6.28211556]]\n",
      "Loss: 0.06264677734051352\n",
      "Weights 1:  [[ -4.23639317   1.05534513 -10.15466057]\n",
      " [ -4.57799983 -10.14885066   1.05440283]]\n",
      "Weights 2:  [[-1.98679144]\n",
      " [-6.31012318]\n",
      " [-6.3282762 ]]\n",
      "Loss: 0.06263633058773316\n",
      "Weights 1:  [[ -4.26985671   1.0618733  -10.23986345]\n",
      " [ -4.61206594 -10.23437953   1.0608077 ]]\n",
      "Weights 2:  [[-1.97086183]\n",
      " [-6.35328521]\n",
      " [-6.3710517 ]]\n",
      "Loss: 0.06262724961022662\n",
      "Weights 1:  [[ -4.30103839   1.06790518 -10.31933109]\n",
      " [ -4.64378647 -10.3141418    1.06673094]]\n",
      "Weights 2:  [[-1.95586956]\n",
      " [-6.39348521]\n",
      " [-6.41089825]]\n",
      "Loss: 0.06261928464610464\n",
      "Weights 1:  [[ -4.33022432   1.07350777 -10.39378062]\n",
      " [ -4.6734577  -10.3888592    1.07223713]]\n",
      "Weights 2:  [[-1.94170486]\n",
      " [-6.4310981 ]\n",
      " [-6.44818616]]\n",
      "Loss: 0.0626122431258468\n",
      "Weights 1:  [[ -4.35765025   1.0787356  -10.46380306]\n",
      " [ -4.70132341 -10.45912644   1.07737888]]\n",
      "Weights 2:  [[-1.92827641]\n",
      " [-6.46643224]\n",
      " [-6.48322003]]\n",
      "Loss: 0.06260597422417302\n",
      "Weights 1:  [[ -4.38351267   1.0836336  -10.52989115]\n",
      " [ -4.72758661 -10.52543929   1.08219959]]\n",
      "Weights 2:  [[-1.91550735]\n",
      " [-6.49974426]\n",
      " [-6.51625343]]\n",
      "Loss: 0.06260035815482072\n",
      "Weights 1:  [[ -4.40797712   1.08823922 -10.59245999]\n",
      " [ -4.75241807 -10.58821537   1.08673546]]\n",
      "Weights 2:  [[-1.90333241]\n",
      " [-6.53125   ]\n",
      " [-6.54749963]]\n",
      "Loss: 0.06259529859397575\n",
      "Weights 1:  [[ -4.43118425   1.09258397 -10.6518625 ]\n",
      " [ -4.7759628  -10.64780969   1.09101699]]\n",
      "Weights 2:  [[-1.89169567]\n",
      " [-6.5611327 ]\n",
      " [-6.57713972]]\n",
      "Loss: 0.06259071721634711\n",
      "Weights 1:  [[ -4.45325466   1.09669462 -10.70840121]\n",
      " [ -4.798345   -10.70452653   1.09507009]]\n",
      "Weights 2:  [[-1.88054882]\n",
      " [-6.5895492 ]\n",
      " [-6.6053287 ]]\n",
      "Loss: 0.06258654968790724\n",
      "Weights 1:  [[ -4.47429245   1.10059408 -10.76233742]\n",
      " [ -4.8196718  -10.75862869   1.09891698]]\n",
      "Weights 2:  [[-1.86984987]\n",
      " [-6.61663479]\n",
      " [-6.63220031]]\n",
      "Loss: 0.06258274268201397\n",
      "Weights 1:  [[ -4.49438813   1.10430211 -10.81389834]\n",
      " [ -4.84003625 -10.81034467   1.10257684]]\n",
      "Weights 2:  [[-1.85956207]\n",
      " [-6.64250696]\n",
      " [-6.65787069]]\n",
      "Loss: 0.06257925162678821\n",
      "Weights 1:  [[ -4.51362087   1.10783588 -10.86328276]\n",
      " [ -4.85951971 -10.85987434   1.10606632]]\n",
      "Weights 2:  [[-1.84965308]\n",
      " [-6.66726838]\n",
      " [-6.68244138]]\n",
      "Loss: 0.06257603898310862\n",
      "Weights 1:  [[ -4.53206031   1.11121036 -10.91066561]\n",
      " [ -4.87819369 -10.9073936    1.10939997]]\n",
      "Weights 2:  [[-1.84009426]\n",
      " [-6.69100929]\n",
      " [-6.70600159]]\n",
      "Loss: 0.0625730729130706\n",
      "Weights 1:  [[ -4.54976803   1.11443874 -10.95620159]\n",
      " [ -4.89612139 -10.95305799   1.1125906 ]]\n",
      "Weights 2:  [[-1.83086016]\n",
      " [-6.71380943]\n",
      " [-6.72863019]]\n",
      "Loss: 0.06257032623949056\n",
      "Weights 1:  [[ -4.56679876   1.11753263 -11.00002822]\n",
      " [ -4.91335891 -10.99700572   1.11564952]]\n",
      "Weights 2:  [[-1.82192802]\n",
      " [-6.73573958]\n",
      " [-6.75039718]]\n",
      "Loss: 0.06256777562492682\n",
      "Weights 1:  [[ -4.58320133   1.12050234 -11.04226823]\n",
      " [ -4.92995631 -11.03936019   1.11858675]]\n",
      "Weights 2:  [[-1.81327746]\n",
      " [-6.75686288]\n",
      " [-6.771365  ]]\n",
      "Loss: 0.06256540091808015\n",
      "Weights 1:  [[ -4.59901949   1.12335707 -11.08303164]\n",
      " [ -4.94595843 -11.08023197   1.12141126]]\n",
      "Weights 2:  [[-1.80489009]\n",
      " [-6.77723587]\n",
      " [-6.7915896 ]]\n",
      "Loss: 0.06256318462911224\n",
      "Weights 1:  [[ -4.61429262   1.12610503 -11.12241747]\n",
      " [ -4.96140557 -11.11972058   1.12413105]]\n",
      "Weights 2:  [[-1.7967493 ]\n",
      " [-6.79690936]\n",
      " [-6.81112125]]\n",
      "Loss: 0.06256111150519304\n",
      "Weights 1:  [[ -4.62905625   1.12875361 -11.16051508]\n",
      " [ -4.9763341  -11.15791583   1.12675332]]\n",
      "Weights 2:  [[-1.78884004]\n",
      " [-6.81592923]\n",
      " [-6.83000532]]\n",
      "Loss: 0.06255916818465163\n",
      "Weights 1:  [[ -4.64334257   1.13130947 -11.1974055 ]\n",
      " [ -4.99077695 -11.19489914   1.12928456]]\n",
      "Weights 2:  [[-1.78114859]\n",
      " [-6.83433698]\n",
      " [-6.8482829 ]]\n",
      "Loss: 0.06255734291327482\n",
      "Weights 1:  [[ -4.65718083   1.13377863 -11.23316231]\n",
      " [ -5.00476403 -11.23074445   1.13173065]]\n",
      "Weights 2:  [[-1.77366245]\n",
      " [-6.85217031]\n",
      " [-6.86599129]]\n",
      "Loss: 0.06255562531011759\n",
      "Weights 1:  [[ -4.67059768   1.13616654 -11.26785262]\n",
      " [ -5.01832259 -11.2655192    1.13409692]]\n",
      "Weights 2:  [[-1.76637019]\n",
      " [-6.86946357]\n",
      " [-6.88316448]]\n",
      "Loss: 0.06255400617303909\n",
      "Weights 1:  [[ -4.68361749   1.13847818 -11.30153776]\n",
      " [ -5.03147751 -11.29928499   1.13638822]]\n",
      "Weights 2:  [[-1.75926129]\n",
      " [-6.88624812]\n",
      " [-6.89983351]]\n",
      "Loss: 0.06255247731632782\n",
      "Weights 1:  [[ -4.69626256   1.14071809 -11.33427394]\n",
      " [ -5.04425158 -11.3320983    1.13860898]]\n",
      "Weights 2:  [[-1.75232611]\n",
      " [-6.90255269]\n",
      " [-6.91602681]]\n",
      "Loss: 0.06255103143440925\n",
      "Weights 1:  [[ -4.7085534    1.14289039 -11.36611277]\n",
      " [ -5.05666574 -11.36401098   1.14076326]]\n",
      "Weights 2:  [[-1.74555573]\n",
      " [-6.91840364]\n",
      " [-6.9317705 ]]\n",
      "Loss: 0.06254966198688089\n",
      "Weights 1:  [[ -4.72050886   1.14499892 -11.39710181]\n",
      " [ -5.06873923 -11.39507081   1.14285477]]\n",
      "Weights 2:  [[-1.73894195]\n",
      " [-6.93382524]\n",
      " [-6.94708859]]\n",
      "Loss: 0.0625483631010843\n",
      "Weights 1:  [[ -4.73214637   1.14704714 -11.42728492]\n",
      " [ -5.08048983 -11.42532184   1.14488695]]\n",
      "Weights 2:  [[-1.73247713]\n",
      " [-6.94883988]\n",
      " [-6.96200324]]\n",
      "Loss: 0.06254712948917306\n",
      "Weights 1:  [[ -4.74348201   1.1490383  -11.45670268]\n",
      " [ -5.09193394 -11.45480482   1.14686293]]\n",
      "Weights 2:  [[-1.72615423]\n",
      " [-6.96346822]\n",
      " [-6.97653493]]\n",
      "Loss: 0.06254595637722493\n",
      "Weights 1:  [[ -4.75453069   1.15097536 -11.48539267]\n",
      " [ -5.10308677 -11.48355751   1.14878563]]\n",
      "Weights 2:  [[-1.71996667]\n",
      " [-6.97772944]\n",
      " [-6.99070262]]\n",
      "Loss: 0.06254483944440634\n",
      "Weights 1:  [[ -4.76530625   1.15286107 -11.51338979]\n",
      " [ -5.11396243 -11.51161496   1.15065775]]\n",
      "Weights 2:  [[-1.71390833]\n",
      " [-6.99164129]\n",
      " [-7.00452391]]\n",
      "Loss: 0.06254377477056779\n",
      "Weights 1:  [[ -4.77582155   1.15469798 -11.54072649]\n",
      " [ -5.12457402 -11.53900976   1.15248178]]\n",
      "Weights 2:  [[-1.70797353]\n",
      " [-7.00522029]\n",
      " [-7.01801515]]\n",
      "Loss: 0.06254275879093796\n",
      "Weights 1:  [[ -4.78608857   1.15648846 -11.56743299]\n",
      " [ -5.13493375 -11.56577225   1.15426004]]\n",
      "Weights 2:  [[-1.70215692]\n",
      " [-7.01848182]\n",
      " [-7.03119158]]\n",
      "Loss: 0.0625417882568213\n",
      "Weights 1:  [[ -4.79611849   1.15823471 -11.59353752]\n",
      " [ -5.14505301 -11.59193078   1.15599469]]\n",
      "Weights 2:  [[-1.69645353]\n",
      " [-7.03144022]\n",
      " [-7.0440674 ]]\n",
      "Loss: 0.06254086020139153\n",
      "Weights 1:  [[ -4.80592175   1.15993878 -11.61906642]\n",
      " [ -5.15494244 -11.6175118    1.15768775]]\n",
      "Weights 2:  [[-1.69085869]\n",
      " [-7.04410889]\n",
      " [-7.05665587]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.06253997190982757\n",
      "Weights 1:  [[ -4.81550812   1.16160258 -11.64404437]\n",
      " [ -5.16461197 -11.64254009   1.15934108]]\n",
      "Weights 2:  [[-1.68536801]\n",
      " [-7.05650036]\n",
      " [-7.06896942]]\n",
      "Loss: 0.06253912089316273\n",
      "Weights 1:  [[ -4.82488677   1.1632279  -11.66849449]\n",
      " [ -5.17407093 -11.66703886   1.16095644]]\n",
      "Weights 2:  [[-1.67997737]\n",
      " [-7.06862636]\n",
      " [-7.08101967]]\n",
      "Input: [[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 0.]\n",
      " [1. 1.]]\n",
      "Actual Output: [array([0.]), array([0.]), array([0.]), array([1.])]\n",
      "Loss: 0.06253830486531926\n",
      "Predicted Output: [array([0.00445139]), array([0.00443996]), array([0.00036182]), array([0.49988645])]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# AND gate dataset\n",
    "X = np.array(([1,0], [0,1], [0, 0], [1,1]), dtype=float)\n",
    "y = np.array(([0], [0], [0], [1]), dtype=float)\n",
    "\n",
    "class NeuralNetwork(object):\n",
    "    def __init__(self):\n",
    "        # Parameters\n",
    "        self.inputSize = 2\n",
    "        self.outputSize = 1\n",
    "        self.hiddenSize = 3\n",
    "        \n",
    "        # Initialization of weights\n",
    "        self.W1 = np.random.randn(self.inputSize, self.hiddenSize) # (3x2) weight matrix from input to hidden layer\n",
    "        self.W2 = np.random.randn(self.hiddenSize, self.outputSize) # (3x1) weight matrix from hidden to output layer\n",
    "        \n",
    "    # Forward propogation through the network\n",
    "    def feedForward(self, X):    \n",
    "        self.z = np.dot(X, self.W1)\n",
    "        self.z2 = self.sigmoid(self.z)\n",
    "        self.z3 = np.dot(self.z2, self.W2)\n",
    "        output = self.sigmoid(self.z3)\n",
    "        return output\n",
    "        \n",
    "    # Activation Function\n",
    "    def sigmoid(self, s, deriv=False):\n",
    "        if (deriv == True):\n",
    "            return s * (1 - s)\n",
    "        return 1/(1 + np.exp(-s))\n",
    "    \n",
    "    # Backward propogate through the network\n",
    "    def backward(self, X, y, output):\n",
    "        # Loss Function\n",
    "        self.output_error = y - output\n",
    "        self.output_delta = self.output_error * self.sigmoid(output, deriv=True)\n",
    "        \n",
    "        self.z2_error = self.output_delta.dot(self.W2.T)\n",
    "        self.z2_delta = self.z2_error * self.sigmoid(self.z2, deriv=True)\n",
    "        \n",
    "        # Ajusting first set (input -> hidden) weights, Learning rate = 1\n",
    "        self.W1 += X.T.dot(self.z2_delta) \n",
    "        # Adjusting second set (hidden -> output) weights, Learning rate = 1\n",
    "        self.W2 += self.z2.T.dot(self.output_delta)\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        output = self.feedForward(X)\n",
    "        self.backward(X, y, output)\n",
    "        \n",
    "NN = NeuralNetwork()\n",
    "\n",
    "# Number of epochs = 50000, Batch size = 1\n",
    "for i in range(50000):\n",
    "    if (i % 1000 == 0):\n",
    "        print(\"Loss: \" + str(np.mean(np.square(y - NN.feedForward(X)))))\n",
    "        # Visualization of weights after every 1000 epochs\n",
    "        print(\"Weights 1: \", NN.W1)\n",
    "        print(\"Weights 2: \", NN.W2)\n",
    "    NN.train(X, y)\n",
    "        \n",
    "print(\"Input: \" + str(X))\n",
    "print(\"Actual Output: \" + str(list(y)))\n",
    "print(\"Loss: \" + str(np.mean(np.square(y - NN.feedForward(X)))))\n",
    "print(\"Predicted Output: \" + str(list(NN.feedForward(X))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4d3d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
