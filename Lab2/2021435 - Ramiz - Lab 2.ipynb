{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8aea833c",
   "metadata": {},
   "source": [
    "# In the following code:\n",
    "### Q1: Neural Network was created with initialization of weights, it takes 2 inputs, 1 hidden layer with 3 neurons, 1 output\n",
    "### Q2: Forward Propogation was implemented\n",
    "### Q3: Mean absolute error was used as a Loss Function\n",
    "### Q4: Learning rate was set to 1 as I wanted fast convergence due to my small dataset, 50000 epochs were used with batch size equal to 1\n",
    "### Q5: I trained the NN with AND gate dataset\n",
    "### Q6: I printed Weights after every 1000 epochs\n",
    "### Q7: I tested the NN with the AND gate dataset and got very good accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc1b4768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2133009643607874\n",
      "Weights 1:  [[-0.95582133 -1.72386724  0.18804933]\n",
      " [ 1.22847233  0.76095939  1.09030045]]\n",
      "Weights 2:  [[-1.66126103]\n",
      " [-0.12800517]\n",
      " [-1.07289274]]\n",
      "Loss: 0.0014205426205617469\n",
      "Weights 1:  [[ 0.912942   -5.35532708 -0.42453909]\n",
      " [-3.86258503  2.12925181  3.0736801 ]]\n",
      "Weights 2:  [[-6.84876362]\n",
      " [-7.32852187]\n",
      " [ 3.7191189 ]]\n",
      "Loss: 0.000559497662783821\n",
      "Weights 1:  [[ 1.13474894 -5.79053534 -0.53795275]\n",
      " [-4.27201587  2.36678869  3.31768815]]\n",
      "Weights 2:  [[-7.20131281]\n",
      " [-8.2098955 ]\n",
      " [ 4.13890632]]\n",
      "Loss: 0.00034218094575906154\n",
      "Weights 1:  [[ 1.24143248 -6.00203313 -0.60234972]\n",
      " [-4.47099373  2.48078542  3.4473532 ]]\n",
      "Weights 2:  [[-7.38498225]\n",
      " [-8.67227326]\n",
      " [ 4.36112385]]\n",
      "Loss: 0.0002449145050975811\n",
      "Weights 1:  [[ 1.31029132 -6.13970899 -0.64770148]\n",
      " [-4.60023324  2.55463283  3.53606181]]\n",
      "Weights 2:  [[-7.5092877 ]\n",
      " [-8.98635025]\n",
      " [ 4.51269094]]\n",
      "Loss: 0.000190116101047925\n",
      "Weights 1:  [[ 1.36056628 -6.24091132 -0.68278221]\n",
      " [-4.69501807  2.60876502  3.60352899]]\n",
      "Weights 2:  [[-7.60315184]\n",
      " [-9.22413366]\n",
      " [ 4.62772735]]\n",
      "Loss: 0.00015507533515438186\n",
      "Weights 1:  [[ 1.39988786 -6.32050465 -0.71141008]\n",
      " [-4.7694086   2.6512582   3.65796904]]\n",
      "Weights 2:  [[-7.67849837]\n",
      " [-9.41540043]\n",
      " [ 4.72041957]]\n",
      "Loss: 0.0001307882201319926\n",
      "Weights 1:  [[ 1.43202864 -6.3858662  -0.73559949]\n",
      " [-4.8303829   2.68610418  3.70359694]]\n",
      "Weights 2:  [[-7.74139772]\n",
      " [-9.57534167]\n",
      " [ 4.79803061]]\n",
      "Loss: 0.00011298686603780104\n",
      "Weights 1:  [[ 1.45911885 -6.44117678 -0.75654575]\n",
      " [-4.88189366  2.7155589   3.74286487]]\n",
      "Weights 2:  [[-7.79535946]\n",
      " [-9.71275439]\n",
      " [ 4.86477715]]\n",
      "Loss: 9.939211550659203e-05\n",
      "Weights 1:  [[ 1.48247426 -6.48902754 -0.77501719]\n",
      " [-4.92638894  2.74101769  3.77732578]]\n",
      "Weights 2:  [[-7.84259462]\n",
      " [-9.83318848]\n",
      " [ 4.92332459]]\n",
      "Loss: 8.867788422225194e-05\n",
      "Weights 1:  [[ 1.50296215 -6.53113183 -0.79153733]\n",
      " [-4.96548625  2.76340172  3.80802545]]\n",
      "Weights 2:  [[-7.88458563]\n",
      " [-9.94036947]\n",
      " [ 4.97546496]]\n",
      "Loss: 8.002095508378613e-05\n",
      "Weights 1:  [[ 1.52118314 -6.56867962 -0.80647908]\n",
      " [-5.00030804  2.78334995  3.8357018 ]]\n",
      "Weights 2:  [[ -7.92237449]\n",
      " [-10.03691894]\n",
      " [  5.02246089]]\n",
      "Loss: 7.288365591191862e-05\n",
      "Weights 1:  [[ 1.53756961 -6.60252989 -0.8201176 ]\n",
      " [-5.03166395  2.80132311  3.86089497]]\n",
      "Weights 2:  [[ -7.95672136]\n",
      " [-10.12475131]\n",
      " [  5.06523541]]\n",
      "Loss: 6.690014448717472e-05\n",
      "Weights 1:  [[ 1.55244276 -6.63332235 -0.83266171]\n",
      " [-5.06015641  2.81766403  3.88401222]]\n",
      "Weights 2:  [[ -7.9881977 ]\n",
      " [-10.20530712]\n",
      " [  5.10448371]]\n",
      "Loss: 6.181296379625576e-05\n",
      "Weights 1:  [[ 1.56604743 -6.66154579 -0.84427373]\n",
      " [-5.08624539  2.83263444  3.90536825]]\n",
      "Weights 2:  [[ -8.01724389]\n",
      " [-10.27969739]\n",
      " [  5.14074241]]\n",
      "Loss: 5.743574168575236e-05\n",
      "Weights 1:  [[ 1.57857439 -6.68758183 -0.85508229]\n",
      " [-5.11028974  2.84643856  3.92521125]]\n",
      "Weights 2:  [[ -8.04420641]\n",
      " [-10.34879699]\n",
      " [  5.17443435]]\n",
      "Loss: 5.3630284261491475e-05\n",
      "Weights 1:  [[ 1.590175   -6.71173394 -0.8651911 ]\n",
      " [-5.13257459  2.85923868  3.94374043]]\n",
      "Weights 2:  [[ -8.06936276]\n",
      " [-10.41330709]\n",
      " [  5.20589863]]\n",
      "Loss: 5.0291980137696384e-05\n",
      "Weights 1:  [[ 1.60097131 -6.73424728 -0.87468499]\n",
      " [-5.15333015  2.87116583  3.96111811]]\n",
      "Weights 2:  [[ -8.09293859]\n",
      " [-10.47379827]\n",
      " [  5.23541137]]\n",
      "Loss: 4.7340201354028764e-05\n",
      "Weights 1:  [[ 1.61106313 -6.75532266 -0.88363422]\n",
      " [-5.17274482  2.88232731  3.97747829]]\n",
      "Weights 2:  [[ -8.11511983]\n",
      " [-10.53074102]\n",
      " [  5.26320034]]\n",
      "Loss: 4.471181479435788e-05\n",
      "Weights 1:  [[ 1.62053303 -6.77512656 -0.89209768]\n",
      " [-5.19097471  2.892812    3.99293289]]\n",
      "Weights 2:  [[ -8.13606152]\n",
      " [-10.58452786]\n",
      " [  5.28945569]]\n",
      "Loss: 4.2356689476097023e-05\n",
      "Weights 1:  [[ 1.62945012 -6.79379847 -0.90012517]\n",
      " [-5.20815054  2.90269437  4.00757633]]\n",
      "Weights 2:  [[ -8.15589425]\n",
      " [-10.63548966]\n",
      " [  5.31433773]]\n",
      "Loss: 4.023451902496031e-05\n",
      "Weights 1:  [[ 1.63787275 -6.81145642 -0.90775922]\n",
      " [-5.22438284  2.9120374   4.02148903]]\n",
      "Weights 2:  [[ -8.17472908]\n",
      " [-10.6839079 ]\n",
      " [  5.33798293]]\n",
      "Loss: 3.831253145515374e-05\n",
      "Weights 1:  [[ 1.64585065 -6.82820111 -0.91503642]\n",
      " [-5.23976586  2.92089479  4.03474001]]\n",
      "Weights 2:  [[ -8.19266119]\n",
      " [-10.730024  ]\n",
      " [  5.36050836]]\n",
      "Loss: 3.656381029435146e-05\n",
      "Weights 1:  [[ 1.65342653 -6.84411914 -0.92198847]\n",
      " [-5.2543806   2.92931272  4.04738895]]\n",
      "Weights 2:  [[ -8.2097728 ]\n",
      " [-10.77404662]\n",
      " [  5.38201525]]\n",
      "Loss: 3.4966044941479104e-05\n",
      "Weights 1:  [[ 1.66063732 -6.8592855  -0.92864306]\n",
      " [-5.26829718  2.93733116  4.05948785]]\n",
      "Weights 2:  [[ -8.22613543]\n",
      " [-10.8161573 ]\n",
      " [  5.40259168]]\n",
      "Loss: 3.3500587571579554e-05\n",
      "Weights 1:  [[ 1.66751516 -6.87376555 -0.93502444]\n",
      " [-5.28157666  2.94498496  4.07108221]]\n",
      "Weights 2:  [[ -8.24181164]\n",
      " [-10.85651497]\n",
      " [  5.42231481]]\n",
      "Loss: 3.215173237912801e-05\n",
      "Weights 1:  [[ 1.67408819 -6.88761659 -0.94115406]\n",
      " [-5.29427255  2.95230462  4.08221217]]\n",
      "Weights 2:  [[ -8.25685648]\n",
      " [-10.89525953]\n",
      " [  5.44125256]]\n",
      "Loss: 3.0906158371849846e-05\n",
      "Weights 1:  [[ 1.68038119 -6.90088911 -0.94705091]\n",
      " [-5.30643198  2.95931704  4.09291323]]\n",
      "Weights 2:  [[ -8.27131867]\n",
      " [-10.93251481]\n",
      " [  5.45946508]]\n",
      "Loss: 2.975249403311732e-05\n",
      "Weights 1:  [[ 1.68641609 -6.91362785 -0.95273191]\n",
      " [-5.31809668  2.96604605  4.10321698]]\n",
      "Weights 2:  [[ -8.2852415 ]\n",
      " [-10.96839091]\n",
      " [  5.47700584]]\n",
      "Loss: 2.8680973876900574e-05\n",
      "Weights 1:  [[ 1.69221236 -6.9258726  -0.95821222]\n",
      " [-5.32930378  2.97251283  4.11315166]]\n",
      "Weights 2:  [[ -8.29866361]\n",
      " [-11.00298618]\n",
      " [  5.49392263]]\n",
      "Loss: 2.768316505405559e-05\n",
      "Weights 1:  [[ 1.6977874  -6.93765892 -0.96350544]\n",
      " [-5.3400864   2.9787363   4.12274261]]\n",
      "Weights 2:  [[ -8.31161965]\n",
      " [-11.03638881]\n",
      " [  5.51025832]]\n",
      "Loss: 2.6751747902855412e-05\n",
      "Weights 1:  [[ 1.7031568  -6.94901873 -0.96862385]\n",
      " [-5.35047429  2.98473345  4.13201263]]\n",
      "Weights 2:  [[ -8.32414079]\n",
      " [-11.06867818]\n",
      " [  5.52605149]]\n",
      "Loss: 2.5880338431870093e-05\n",
      "Weights 1:  [[ 1.70833458 -6.95998076 -0.97357855]\n",
      " [-5.36049419  2.99051956  4.14098234]]\n",
      "Weights 2:  [[ -8.3362552 ]\n",
      " [-11.09992602]\n",
      " [  5.54133702]]\n",
      "Loss: 2.506334368386553e-05\n",
      "Weights 1:  [[ 1.7133334  -6.97057095 -0.97837961]\n",
      " [-5.37017026  2.99610843  4.14967045]]\n",
      "Weights 2:  [[ -8.34798839]\n",
      " [-11.13019735]\n",
      " [  5.55614652]]\n",
      "Loss: 2.429584309399415e-05\n",
      "Weights 1:  [[ 1.71816471 -6.98081284 -0.98303621]\n",
      " [-5.3795244   3.00151259  4.15809396]]\n",
      "Weights 2:  [[ -8.35936355]\n",
      " [-11.15955128]\n",
      " [  5.57050875]]\n",
      "Loss: 2.3573490555047354e-05\n",
      "Weights 1:  [[ 1.72283894 -6.99072782 -0.98755673]\n",
      " [-5.38857651  3.0067434   4.16626837]]\n",
      "Weights 2:  [[ -8.37040183]\n",
      " [-11.18804173]\n",
      " [  5.58444994]]\n",
      "Loss: 2.2892433096060924e-05\n",
      "Weights 1:  [[ 1.72736557 -7.0003354  -0.99194884]\n",
      " [-5.39734473  3.01181123  4.17420789]]\n",
      "Weights 2:  [[ -8.38112254]\n",
      " [-11.21571799]\n",
      " [  5.59799405]]\n",
      "Loss: 2.2249242979491823e-05\n",
      "Weights 1:  [[ 1.73175327 -7.00965342 -0.99621959]\n",
      " [-5.40584561  3.01672557  4.18192553]]\n",
      "Weights 2:  [[ -8.3915434 ]\n",
      " [-11.24262525]\n",
      " [  5.6111631 ]]\n",
      "Loss: 2.164086070508264e-05\n",
      "Weights 1:  [[ 1.73600997 -7.0186982  -1.00037545]\n",
      " [-5.41409435  3.0214951   4.18943324]]\n",
      "Weights 2:  [[ -8.40168069]\n",
      " [-11.26880505]\n",
      " [  5.62397729]]\n",
      "Loss: 2.106454693157395e-05\n",
      "Weights 1:  [[ 1.74014295 -7.02748478 -1.00442239]\n",
      " [-5.42210489  3.02612779  4.19674205]]\n",
      "Weights 2:  [[ -8.41154938]\n",
      " [-11.29429566]\n",
      " [  5.63645525]]\n",
      "Loss: 2.0517841731110784e-05\n",
      "Weights 1:  [[ 1.74415893 -7.03602697 -1.00836593]\n",
      " [-5.42989007  3.030631    4.20386214]]\n",
      "Weights 2:  [[ -8.42116332]\n",
      " [-11.31913239]\n",
      " [  5.64861417]]\n",
      "Loss: 1.9998529905010805e-05\n",
      "Weights 1:  [[ 1.74806408 -7.04433755 -1.01221119]\n",
      " [-5.43746173  3.03501149  4.21080293]]\n",
      "Weights 2:  [[ -8.4305353 ]\n",
      " [-11.34334793]\n",
      " [  5.66046997]]\n",
      "Loss: 1.950461133523643e-05\n",
      "Weights 1:  [[ 1.75186412 -7.05242829 -1.0159629 ]\n",
      " [-5.44483082  3.03927555  4.21757315]]\n",
      "Weights 2:  [[ -8.43967716]\n",
      " [-11.36697255]\n",
      " [  5.67203738]]\n",
      "Loss: 1.9034275539453885e-05\n",
      "Weights 1:  [[ 1.75556433 -7.06031014 -1.01962548]\n",
      " [-5.45200746  3.04342896  4.2241809 ]]\n",
      "Weights 2:  [[ -8.44859991]\n",
      " [-11.39003439]\n",
      " [  5.68333012]]\n",
      "Loss: 1.8585879750961217e-05\n",
      "Weights 1:  [[ 1.75916962 -7.06799325 -1.02320303]\n",
      " [-5.45900107  3.04747713  4.23063374]]\n",
      "Weights 2:  [[ -8.45731379]\n",
      " [-11.41255962]\n",
      " [  5.69436093]]\n",
      "Loss: 1.815792996714194e-05\n",
      "Weights 1:  [[ 1.76268454 -7.07548703 -1.02669937]\n",
      " [-5.46582039  3.05142505  4.2369387 ]]\n",
      "Weights 2:  [[ -8.46582834]\n",
      " [-11.43457261]\n",
      " [  5.70514168]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.7749064508145376e-05\n",
      "Weights 1:  [[ 1.76611335 -7.08280029 -1.03011809]\n",
      " [-5.47247356  3.05527739  4.24310233]]\n",
      "Weights 2:  [[ -8.47415244]\n",
      " [-11.45609613]\n",
      " [  5.71568346]]\n",
      "Loss: 1.735803970658196e-05\n",
      "Weights 1:  [[ 1.76945999 -7.08994121 -1.03346251]\n",
      " [-5.47896817  3.05903851  4.2491308 ]]\n",
      "Weights 2:  [[ -8.48229442]\n",
      " [-11.47715145]\n",
      " [  5.72599664]]\n",
      "Loss: 1.6983717413065972e-05\n",
      "Weights 1:  [[ 1.77272815 -7.09691746 -1.03673578]\n",
      " [-5.48531131  3.06271246  4.25502983]]\n",
      "Weights 2:  [[ -8.49026206]\n",
      " [-11.4977585 ]\n",
      " [  5.73609093]]\n",
      "Loss: 1.6625054054561267e-05\n",
      "Weights 1:  [[ 1.7759213  -7.10373619 -1.03994083]\n",
      " [-5.49150961  3.06630304  4.26080483]]\n",
      "Weights 2:  [[ -8.49806266]\n",
      " [-11.51793595]\n",
      " [  5.74597543]]\n",
      "Input: [[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 0.]\n",
      " [1. 1.]]\n",
      "Actual Output: [array([0.]), array([0.]), array([0.]), array([1.])]\n",
      "Loss: 1.628109102514108e-05\n",
      "Predicted Output: [array([0.00305767]), array([0.00456635]), array([0.00078906]), array([0.99414331])]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# AND gate dataset\n",
    "X = np.array(([1,0], [0,1], [0, 0], [1,1]), dtype=float)\n",
    "y = np.array(([0], [0], [0], [1]), dtype=float)\n",
    "\n",
    "class NeuralNetwork(object):\n",
    "    def __init__(self):\n",
    "        # Parameters\n",
    "        self.inputSize = 2\n",
    "        self.outputSize = 1\n",
    "        self.hiddenSize = 3\n",
    "        \n",
    "        # Initialization of weights\n",
    "        self.W1 = np.random.randn(self.inputSize, self.hiddenSize) # (3x2) weight matrix from input to hidden layer\n",
    "        self.W2 = np.random.randn(self.hiddenSize, self.outputSize) # (3x1) weight matrix from hidden to output layer\n",
    "        \n",
    "    # Forward propogation through the network\n",
    "    def feedForward(self, X):    \n",
    "        self.z = np.dot(X, self.W1)\n",
    "        self.z2 = self.sigmoid(self.z)\n",
    "        self.z3 = np.dot(self.z2, self.W2)\n",
    "        output = self.sigmoid(self.z3)\n",
    "        return output\n",
    "        \n",
    "    # Activation Function\n",
    "    def sigmoid(self, s, deriv=False):\n",
    "        if (deriv == True):\n",
    "            return s * (1 - s)\n",
    "        return 1/(1 + np.exp(-s))\n",
    "    \n",
    "    # Backward propogate through the network\n",
    "    def backward(self, X, y, output):\n",
    "        # Loss Function\n",
    "        self.output_error = y - output\n",
    "        self.output_delta = self.output_error * self.sigmoid(output, deriv=True)\n",
    "        \n",
    "        self.z2_error = self.output_delta.dot(self.W2.T)\n",
    "        self.z2_delta = self.z2_error * self.sigmoid(self.z2, deriv=True)\n",
    "        \n",
    "        # Ajusting first set (input -> hidden) weights, Learning rate = 1\n",
    "        self.W1 += X.T.dot(self.z2_delta) \n",
    "        # Adjusting second set (hidden -> output) weights, Learning rate = 1\n",
    "        self.W2 += self.z2.T.dot(self.output_delta)\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        output = self.feedForward(X)\n",
    "        self.backward(X, y, output)\n",
    "        \n",
    "NN = NeuralNetwork()\n",
    "\n",
    "# Number of epochs = 50000, Batch size = 1\n",
    "for i in range(50000):\n",
    "    if (i % 1000 == 0):\n",
    "        print(\"Loss: \" + str(np.mean(np.square(y - NN.feedForward(X)))))\n",
    "        # Visualization of weights after every 1000 epochs\n",
    "        print(\"Weights 1: \", NN.W1)\n",
    "        print(\"Weights 2: \", NN.W2)\n",
    "    NN.train(X, y)\n",
    "        \n",
    "print(\"Input: \" + str(X))\n",
    "print(\"Actual Output: \" + str(list(y)))\n",
    "print(\"Loss: \" + str(np.mean(np.square(y - NN.feedForward(X)))))\n",
    "print(\"Predicted Output: \" + str(list(NN.feedForward(X))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4d3d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
