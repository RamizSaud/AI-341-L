{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7dkYYACQYDtq"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-3YNIJ_1YDtq"
   },
   "outputs": [],
   "source": [
    "# define tokenized senences as training data\n",
    "tokenized_sentences = [['Hello','This','is','python','training','by','Sarim'],\n",
    "             ['Hello','This','is','Java','training','by','Sarim'],\n",
    "             ['Hello','This','is','Data Science','training','by','Unfold','Data','Science'],\n",
    "             ['Hello','This','is','programming','training','']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xKbWg239YDtq"
   },
   "outputs": [],
   "source": [
    "# training word2vec model\n",
    "from gensim.models import Word2Vec\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "mymodel = Word2Vec(tokenized_sentences, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1697455679992,
     "user": {
      "displayName": "Fatima Khalid",
      "userId": "01929709676171667857"
     },
     "user_tz": -300
    },
    "id": "p89nR3g6YDtr",
    "outputId": "1eef35f9-f1a5-4689-ed82-c6f14567931b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=14, vector_size=100, alpha=0.025>\n"
     ]
    }
   ],
   "source": [
    "# summarizing the loaded model\n",
    "print(mymodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5xjW6kTKYDts"
   },
   "outputs": [],
   "source": [
    "# Get the list of words in the vocabulary\n",
    "words = mymodel.wv.index_to_key\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 395,
     "status": "ok",
     "timestamp": 1697455688402,
     "user": {
      "displayName": "Fatima Khalid",
      "userId": "01929709676171667857"
     },
     "user_tz": -300
    },
    "id": "crpd9pVuYDts",
    "outputId": "b8ae2c2a-16ca-4cb3-8d43-fd8054d2fee1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['training', 'is', 'This', 'Hello', 'by', 'Sarim', '', 'programming', 'Science', 'Data', 'Unfold', 'Data Science', 'Java', 'python']\n"
     ]
    }
   ],
   "source": [
    "# summarize vocabulary\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 431,
     "status": "ok",
     "timestamp": 1697455694320,
     "user": {
      "displayName": "Fatima Khalid",
      "userId": "01929709676171667857"
     },
     "user_tz": -300
    },
    "id": "H3VZKOg4YDtt",
    "outputId": "9ff08a6c-681f-4c64-edca-8ae4748552f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8.2426779e-03  9.2993546e-03 -1.9766092e-04 -1.9672764e-03\n",
      "  4.6036304e-03 -4.0953159e-03  2.7431143e-03  6.9399667e-03\n",
      "  6.0654259e-03 -7.5107943e-03  9.3823504e-03  4.6718083e-03\n",
      "  3.9661205e-03 -6.2435055e-03  8.4599797e-03 -2.1501649e-03\n",
      "  8.8251876e-03 -5.3620026e-03 -8.1294188e-03  6.8245591e-03\n",
      "  1.6711927e-03 -2.1985089e-03  9.5136007e-03  9.4938548e-03\n",
      " -9.7740470e-03  2.5052286e-03  6.1566923e-03  3.8724565e-03\n",
      "  2.0227872e-03  4.3050171e-04  6.7363144e-04 -3.8206363e-03\n",
      " -7.1402504e-03 -2.0888723e-03  3.9238976e-03  8.8186832e-03\n",
      "  9.2591504e-03 -5.9759365e-03 -9.4026709e-03  9.7643770e-03\n",
      "  3.4297847e-03  5.1661171e-03  6.2823449e-03 -2.8042626e-03\n",
      "  7.3227035e-03  2.8302716e-03  2.8710044e-03 -2.3803699e-03\n",
      " -3.1282497e-03 -2.3701417e-03  4.2764368e-03  7.6057913e-05\n",
      " -9.5842788e-03 -9.6655441e-03 -6.1481940e-03 -1.2856961e-04\n",
      "  1.9974159e-03  9.4319675e-03  5.5843508e-03 -4.2906962e-03\n",
      "  2.7831673e-04  4.9643586e-03  7.6983096e-03 -1.1442233e-03\n",
      "  4.3234206e-03 -5.8143795e-03 -8.0419064e-04  8.1000505e-03\n",
      " -2.3600650e-03 -9.6634552e-03  5.7792603e-03 -3.9298222e-03\n",
      " -1.2228728e-03  9.9805174e-03 -2.2563506e-03 -4.7570644e-03\n",
      " -5.3293873e-03  6.9808899e-03 -5.7088719e-03  2.1136629e-03\n",
      " -5.2556600e-03  6.1207139e-03  4.3573068e-03  2.6063549e-03\n",
      " -1.4910829e-03 -2.7460635e-03  8.9929365e-03  5.2157748e-03\n",
      " -2.1625196e-03 -9.4703101e-03 -7.4260519e-03 -1.0637414e-03\n",
      " -7.9494715e-04 -2.5629092e-03  9.6827205e-03 -4.5852066e-04\n",
      "  5.8737611e-03 -7.4475873e-03 -2.5060738e-03 -5.5498634e-03]\n"
     ]
    }
   ],
   "source": [
    "# access word vector for one word \"training\"\n",
    "print(mymodel.wv['Hello'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "error",
     "timestamp": 1696838102915,
     "user": {
      "displayName": "Fatima Khalid",
      "userId": "01929709676171667857"
     },
     "user_tz": -300
    },
    "id": "R8uMNM3NYDtu",
    "outputId": "19bc8fa1-4a6d-47a9-abb2-a06dd4b8bbba"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8903a9ae4639>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#try finding most similar words for word \"Data\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmymodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"laptop\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m         \u001b[0;31m# compute the weighted average of all keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mean_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_normalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpost_normalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m         all_keys = [\n\u001b[1;32m    843\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_KEY_TYPES\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_index_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_mean_vector\u001b[0;34m(self, keys, weights, pre_normalize, post_normalize, ignore_missing)\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mtotal_weight\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mignore_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Key '{key}' not present in vocabulary\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtotal_weight\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Key 'laptop' not present in vocabulary\""
     ]
    }
   ],
   "source": [
    "#try finding most similar words for word \"Data\"\n",
    "mymodel.wv.most_similar(\"laptop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TAHy_6ddYDtw"
   },
   "source": [
    "# Create Embedding model using Keras Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WlkTwkluYDtw"
   },
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "# define documents\n",
    "Sent = ['Hello, how are you',\n",
    "        'how are you',\n",
    "        'how are you doing',\n",
    "        'I am doing great',\n",
    "        'I am doing good',\n",
    "        'I am good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0jqLt-ZPYDtw"
   },
   "outputs": [],
   "source": [
    "# defining class labels\n",
    "sent_labels = array([1,1,1,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1696838142054,
     "user": {
      "displayName": "Fatima Khalid",
      "userId": "01929709676171667857"
     },
     "user_tz": -300
    },
    "id": "QCU_r6-qYDtw",
    "outputId": "80323203-aa3e-4810-fb09-22519334eb93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 12, 12, 9], [12, 12, 9], [12, 12, 9, 25], [14, 10, 25, 16], [14, 10, 25, 10], [14, 10, 10]]\n"
     ]
    }
   ],
   "source": [
    "# integer encoding of the documents\n",
    "my_vocab_size = 30\n",
    "encoded_sent = [one_hot(i, my_vocab_size) for i in Sent]\n",
    "print(encoded_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1696838146156,
     "user": {
      "displayName": "Fatima Khalid",
      "userId": "01929709676171667857"
     },
     "user_tz": -300
    },
    "id": "0DlCvnq7YDtx",
    "outputId": "44637b39-e5df-4458-de4c-968a999691f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  6 12 12  9]\n",
      " [ 0  0 12 12  9]\n",
      " [ 0 12 12  9 25]\n",
      " [ 0 14 10 25 16]\n",
      " [ 0 14 10 25 10]\n",
      " [ 0  0 14 10 10]]\n"
     ]
    }
   ],
   "source": [
    "# padding documents to a max length =5\n",
    "length = 5\n",
    "padded_sent = pad_sequences(encoded_sent, maxlen=length, padding='pre')\n",
    "print(padded_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gtr9cXdvYDtx"
   },
   "outputs": [],
   "source": [
    "# defining the model\n",
    "mymodel = Sequential()\n",
    "mymodel.add(Embedding(my_vocab_size, 8, input_length=length))\n",
    "mymodel.add(Flatten())\n",
    "mymodel.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AfcHv5cOYDtx"
   },
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "mymodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1797,
     "status": "ok",
     "timestamp": 1696838203204,
     "user": {
      "displayName": "Fatima Khalid",
      "userId": "01929709676171667857"
     },
     "user_tz": -300
    },
    "id": "7B6SBgI-YDtx",
    "outputId": "78683b6f-98c2-413a-94ab-9040aa29099a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 763ms/step - loss: 0.7013 - accuracy: 0.1667\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6991 - accuracy: 0.1667\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6968 - accuracy: 0.3333\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6945 - accuracy: 0.6667\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6923 - accuracy: 0.6667\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6900 - accuracy: 0.6667\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6878 - accuracy: 0.6667\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6855 - accuracy: 0.8333\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6833 - accuracy: 0.8333\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6811 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6788 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6766 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6743 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6721 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6699 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6676 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6654 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6631 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6608 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6585 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6563 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6540 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6516 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6493 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6470 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6446 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6423 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6399 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6375 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6350 - accuracy: 1.0000\n",
      "Accuracy: 100.000000\n"
     ]
    }
   ],
   "source": [
    "# fiting  the model\n",
    "mymodel.fit(padded_sent, sent_labels, epochs=30)\n",
    "\n",
    "# evaluate the model\n",
    "modelloss, modelaccuracy = mymodel.evaluate(padded_sent, sent_labels, verbose=0)\n",
    "print('Accuracy: %f' % (modelaccuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hVItmLRYYDty"
   },
   "source": [
    "# The Prediction part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SSYDr8_tYDty"
   },
   "outputs": [],
   "source": [
    "mysent_to_predict = ['how are you Sania',\n",
    "        'I am good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1696838215504,
     "user": {
      "displayName": "Fatima Khalid",
      "userId": "01929709676171667857"
     },
     "user_tz": -300
    },
    "id": "b7q_Iw3oYDty",
    "outputId": "d71470f2-19ea-47ca-c495-9084792d4ce1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12, 12, 9, 3], [14, 10, 10]]\n"
     ]
    }
   ],
   "source": [
    "# integer encode the documents\n",
    "vocab_size = 30\n",
    "encoded = [one_hot(d, vocab_size) for d in mysent_to_predict]\n",
    "print(encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1696838217614,
     "user": {
      "displayName": "Fatima Khalid",
      "userId": "01929709676171667857"
     },
     "user_tz": -300
    },
    "id": "vbOQ4Zv7YDty",
    "outputId": "c39e7bd7-6d85-4285-f1e8-abc37d1bfac0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 12 12  9  3]\n",
      " [ 0  0 14 10 10]]\n"
     ]
    }
   ],
   "source": [
    "# pad documents to a max length of 5 words\n",
    "max_length = 5\n",
    "mypadded = pad_sequences(encoded, maxlen=max_length, padding='pre')\n",
    "print(mypadded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 515,
     "status": "ok",
     "timestamp": 1696838318691,
     "user": {
      "displayName": "Fatima Khalid",
      "userId": "01929709676171667857"
     },
     "user_tz": -300
    },
    "id": "tfCbjLVfYDtz",
    "outputId": "cec82650-6a85-4abd-fb17-30a1a3022ed0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "[1, 0]\n"
     ]
    }
   ],
   "source": [
    "predictions = mymodel.predict(mypadded)\n",
    "\n",
    "# Define a threshold for classification (e.g., 0.5)\n",
    "threshold = 0.5\n",
    "\n",
    "# Convert predicted probabilities to binary class labels\n",
    "predicted_classes = [1 if prediction >= threshold else 0 for prediction in predictions]\n",
    "\n",
    "# Print the predicted class labels\n",
    "print(predicted_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HbXDX4QDYDtz"
   },
   "source": [
    "# Task\n",
    "\n",
    "Sentiment Prediction\n",
    "\n",
    "1. Create a list of new sentences or documents with unknown sentiments.\n",
    "2. Preprocess the new text data(tokenization, removing stop words and punctuation marks).\n",
    "3. Use the custom architecture to train the model and predict sentiments for the new text data.\n",
    "4. Apply a threshold to the predicted probabilities to determine the final sentiment labels (e.g., positive or negative).\n",
    "5. Evaluate the accuracy of the sentiment predictions."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1IYhqbMxV5IFcwcOGHlTGPFhrn45uf95T",
     "timestamp": 1696839764335
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
