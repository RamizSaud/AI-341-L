{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8299c1a",
   "metadata": {},
   "source": [
    "# Lab 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "512c05fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7abd42",
   "metadata": {},
   "source": [
    "# Single Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ca3c198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = np.random.randn(1,3)\n",
    "weights = np.random.randn(3,1)\n",
    "bias = np.random.random()\n",
    "activation = lambda x: 1 if x > 0 else 0\n",
    "activation(inputs.dot(weights)+bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a202a4f",
   "metadata": {},
   "source": [
    "# Single Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "62b6904c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = np.random.randn(1,3)\n",
    "weights = np.random.randn(3,3,1)\n",
    "biases = np.random.randn(3,1)\n",
    "weighted_output = inputs.dot(weights)+biases\n",
    "[activation(i) for i in weighted_output.flatten()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccfc773",
   "metadata": {},
   "source": [
    "# Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d2febb3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = np.random.randn(1,3)\n",
    "for i in range(3):\n",
    "    weights = np.random.randn(3,3,1)\n",
    "    biases = np.random.randn(3,1)\n",
    "    weighted_output = inputs.dot(weights)+biases\n",
    "    inputs = np.array([activation(i) for i in weighted_output.flatten()])\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d30f55",
   "metadata": {},
   "source": [
    "# Dynamic Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554e21fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self, input_size):\n",
    "        self.input_size = input_size\n",
    "        self.layers = []\n",
    "        self.layer_count = -1\n",
    "        self.lr = 1\n",
    "        \n",
    "    def add_layer(self,neuron_count,activation=\"sigmoid\"):\n",
    "        self.layer_count+=1\n",
    "        if self.layer_count==0:\n",
    "            self.layers.append({'weights':np.random.randn(self.input_size, neuron_count),\n",
    "                                'biases':np.random.randn(neuron_count),\n",
    "                                'activation':activation,\n",
    "                                'neuron_count':neuron_count,\n",
    "                                'weighted_output':0,\n",
    "                                'activated_output':0})\n",
    "        else:\n",
    "            self.layers.append({'weights':np.random.randn(self.layers[self.layer_count-1]['neuron_count'], neuron_count),\n",
    "                                'biases':np.random.randn(neuron_count),\n",
    "                                'activation':activation,\n",
    "                                'neuron_count':neuron_count,\n",
    "                                'weighted_output':0,\n",
    "                                'activated_output':0})\n",
    "            \n",
    "    def sigmoid(self, s, deriv=False):\n",
    "        if (deriv == True):\n",
    "            return s * (1 - s)\n",
    "        return 1/(1 + np.exp(-s))\n",
    "    \n",
    "    def feed_forward(self,X):\n",
    "        for layer in range(self.layer_count+1):\n",
    "            if layer==0:\n",
    "                z = np.dot(X,self.layers[layer]['weights']) #+ self.layers[layer]['biases']\n",
    "                self.layers[layer]['weighted_output'] = z\n",
    "                if self.layers[layer]['activation']==\"sigmoid\":\n",
    "                    self.layers[layer]['activated_output'] = self.sigmoid(z)\n",
    "            else:\n",
    "                z = np.dot(self.layers[layer-1]['activated_output'],self.layers[layer]['weights']) #+ self.layers[layer]['biases']\n",
    "                self.layers[layer]['weighted_output'] = z\n",
    "                if self.layers[layer]['activation']==\"sigmoid\":\n",
    "                    self.layers[layer]['activated_output'] = self.sigmoid(z)\n",
    "        return self.layers[layer]['activated_output']\n",
    "                    \n",
    "    def back_propogation(self,y):\n",
    "        error = ((y - self.layers[self.layer_count]['activated_output'])**2)/2\n",
    "        e_f = -(y - self.layers[self.layer_count]['activated_output'])\n",
    "        for layer in range(self.layer_count,-1,-1):\n",
    "            f_zf = e_f * self.sigmoid(self.layers[layer]['activated_output'],deriv=True)\n",
    "            zf_w = self.layers[layer-1]['activated_output'].T.dot(f_zf)\n",
    "            e_f = f_zf.dot(self.layers[layer]['weights'].T)\n",
    "            self.layers[layer]['weights'] -= self.lr*zf_w\n",
    "        return error\n",
    "            \n",
    "    def fit(self, X, y, batch_size=32, epoch=1000):\n",
    "        for i in range(epoch):\n",
    "            index = list(np.random.randint(X.shape[0],size=batch_size))\n",
    "            batch_X = X[index]\n",
    "            batch_y = y[index]\n",
    "            for X_t,y_t in zip(batch_X,batch_y):\n",
    "                output = self.feed_forward(np.array([X_t]))\n",
    "                error = self.back_propogation(np.array([y_t]))\n",
    "            if (i%100==0):\n",
    "                print(\"MSE: \",error[0][0])\n",
    "        print(\"Actual Output: \",y_t)\n",
    "        print(\"Predicted Output: \",output)\n",
    "\n",
    "X = np.random.randint(5,15,size=10)\n",
    "y = X*2\n",
    "X = X/np.amax(X,axis=0)\n",
    "y = y/np.amax(y,axis=0)\n",
    "\n",
    "nn = NN(1)\n",
    "nn.add_layer(3)\n",
    "nn.add_layer(1)\n",
    "nn.fit(X.reshape(X.shape[0],1),y.reshape(y.shape[0],1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2955d5",
   "metadata": {},
   "source": [
    "# Reshaping Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ea773016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.88783875]\n",
      " [-0.43435768]\n",
      " [-0.95900966]]\n",
      "[[ 0.88783875 -0.43435768 -0.95900966]]\n",
      "[ 0.88783875 -0.43435768 -0.95900966]\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randn(3,1)\n",
    "print(x)\n",
    "print(x.reshape(1,3))\n",
    "print(x.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b011b1",
   "metadata": {},
   "source": [
    "# Lab 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c9edf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dropout, BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45312d99",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8be21da",
   "metadata": {},
   "source": [
    "## My data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bc4f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ade448",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220b6774",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# create scaler\n",
    "scaler = StandardScaler()\n",
    "# fit scaler on data\n",
    "scaler.fit(data)\n",
    "# apply transform\n",
    "standardized = scaler.transform(data)\n",
    "# inverse transform\n",
    "inverse = scaler.inverse_transform(standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad6c384",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# create scaler\n",
    "scaler = MinMaxScaler()\n",
    "# fit scaler on data\n",
    "scaler.fit(data)\n",
    "# apply transform\n",
    "normalized = scaler.transform(data)\n",
    "# inverse transform\n",
    "inverse = scaler.inverse_transform(normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918202b1",
   "metadata": {},
   "source": [
    "## Sir data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d869f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43250b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_2 = x_train/255\n",
    "x_test_2 = x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db74c561",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_2 = tf.keras.utils.to_categorical(y_train, num_classes=10, dtype='float32')\n",
    "y_test_2 = tf.keras.utils.to_categorical(y_test, num_classes=10, dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11ac5ab",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cf82d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    Flatten(input_shape=(32,32,3)),\n",
    "    Dense(2048, activation = 'relu'),\n",
    "    Dense(1024, activation = 'relu'),\n",
    "    Dense(512, activation = 'relu'),\n",
    "    Dense(256, activation = 'relu'),\n",
    "    Dense(10, activation = 'softmax')\n",
    "])\n",
    "model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train_2, y_train_2, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8addffe",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed696ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(32, 32, 3)),\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train_2, y_train_2, epochs=10, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b7f8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f82051",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X[test], Y[test], verbose=0)\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b83892",
   "metadata": {},
   "source": [
    "# Lab work of CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8b6d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = Image.open(\"ali.jpg\")\n",
    "# Convert the image to grayscale\n",
    "gray_image = image.convert(\"L\")\n",
    "\n",
    "# Save the grayscale image if needed\n",
    "gray_image.save(\"ali_gray.jpg\")\n",
    "\n",
    "plt.imshow(gray_image, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6233b1",
   "metadata": {},
   "source": [
    "## Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4a755e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "image = np.array(image)\n",
    "\n",
    "# Convert the image to grayscale if it's not already\n",
    "if len(image.shape) == 3 and image.shape[2] == 3:\n",
    "    image = np.mean(image, axis=2).astype(np.uint8)\n",
    "\n",
    "# Convert the image to a tensor\n",
    "image_tensor = tf.constant(image, dtype=tf.float32)\n",
    "\n",
    "# Reshape the image tensor to add a batch dimension\n",
    "image_tensor = tf.reshape(image_tensor, [1, image_tensor.shape[0], image_tensor.shape[1], 1])\n",
    "\n",
    "# Define a 3x3 convolution kernel\n",
    "kernel = np.array([[1, 1, 1],\n",
    "                   [1, -8, 1],\n",
    "                   [1, 1, 1]], dtype=np.float32)\n",
    "kernel = tf.constant(kernel, dtype=tf.float32)\n",
    "kernel = tf.reshape(kernel, [3, 3, 1, 1])\n",
    "\n",
    "# Apply convolution operation\n",
    "output = tf.nn.conv2d(image_tensor, kernel, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "\n",
    "# Remove the batch dimension from the output\n",
    "output = tf.squeeze(output)\n",
    "\n",
    "# Normalize the output to the range [0, 255]\n",
    "output = tf.clip_by_value(output, 0.0, 255.0)\n",
    "output = tf.round(output)\n",
    "output = tf.cast(output, dtype=tf.uint8)\n",
    "\n",
    "# Convert the output tensor to a NumPy array\n",
    "output_array = output.numpy()\n",
    "\n",
    "# Save the resulting image\n",
    "output_image = Image.fromarray(output_array)\n",
    "output_image.save(\"convolution_result.jpg\")  # Replace with your desired output file path\n",
    "\n",
    "# Display the output image using matplotlib\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(Image.open(\"ali.jpg\"))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Convolved Image\")\n",
    "plt.imshow(output_image)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5ab18f",
   "metadata": {},
   "source": [
    "## Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59b8b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the image file\n",
    "image = Image.open(\"ali.jpg\")  # Replace \"sample.jpg\" with the path to your image\n",
    "image = np.array(image)\n",
    "\n",
    "# Convert the image to grayscale if it's not already\n",
    "if len(image.shape) == 3 and image.shape[2] == 3:\n",
    "    image = np.mean(image, axis=2).astype(np.uint8)\n",
    "\n",
    "# Convert the image to a tensor\n",
    "image_tensor = tf.constant(image, dtype=tf.float32)\n",
    "\n",
    "# Reshape the image tensor to add a batch dimension\n",
    "image_tensor = tf.reshape(image_tensor, [1, image_tensor.shape[0], image_tensor.shape[1], 1])\n",
    "\n",
    "# Apply max pooling\n",
    "max_pooled = tf.nn.max_pool2d(image_tensor, ksize=(2, 2), strides=(2, 2), padding=\"VALID\")\n",
    "\n",
    "# Apply min pooling\n",
    "min_pooled = -tf.nn.max_pool2d(-image_tensor, ksize=(2, 2), strides=(2, 2), padding=\"VALID\")\n",
    "\n",
    "# Remove the batch dimension from the pooled images\n",
    "max_pooled = tf.squeeze(max_pooled)\n",
    "min_pooled = tf.squeeze(min_pooled)\n",
    "\n",
    "# Display the original, max-pooled, and min-pooled images using matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Original Image\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(Image.open(\"ali.jpg\"))\n",
    "plt.axis('off')\n",
    "\n",
    "# Max Pooled Image\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Max Pooled Image\")\n",
    "plt.imshow(max_pooled)\n",
    "plt.axis('off')\n",
    "\n",
    "# Min Pooled Image\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Min Pooled Image\")\n",
    "plt.imshow(min_pooled)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88a14ff",
   "metadata": {},
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478aafd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image using TensorFlow (assuming you have TensorFlow Dataset)\n",
    "image_path = \"ali.jpg\"  # Replace with the path to your image\n",
    "image = tf.io.read_file(image_path)\n",
    "image = tf.image.decode_image(image, channels=3)  # Decode the image (3 channels for RGB)\n",
    "\n",
    "# Define the amount of padding you want (in pixels)\n",
    "top_padding = 50\n",
    "bottom_padding = 50\n",
    "left_padding = 30\n",
    "right_padding = 30\n",
    "\n",
    "# Apply padding to the image\n",
    "padded_image = tf.image.pad_to_bounding_box(\n",
    "    image,\n",
    "    offset_height=top_padding,\n",
    "    offset_width=left_padding,\n",
    "    target_height=image.shape[0] + top_padding + bottom_padding,\n",
    "    target_width=image.shape[1] + left_padding + right_padding\n",
    ")\n",
    "\n",
    "# Convert the TensorFlow tensor to a NumPy array for visualization\n",
    "padded_array = padded_image.numpy()\n",
    "\n",
    "padded_image = Image.fromarray(padded_array)\n",
    "padded_image.save(\"padded_image.jpg\")  # Replace with your desired output file path\n",
    "\n",
    "# Display the original and padded images using Matplotlib\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Padded Image\")\n",
    "plt.imshow(padded_image)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad09b8c",
   "metadata": {},
   "source": [
    "## Stride 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44084cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the image file\n",
    "image = Image.open(\"ali.jpg\")  # Replace \"sample.jpg\" with the path to your image\n",
    "image = np.array(image)\n",
    "\n",
    "# Convert the image to grayscale if it's not already\n",
    "if len(image.shape) == 3 and image.shape[2] == 3:\n",
    "    image = np.mean(image, axis=2).astype(np.uint8)\n",
    "\n",
    "# Convert the image to a tensor\n",
    "image_tensor = tf.constant(image, dtype=tf.float32)\n",
    "\n",
    "# Reshape the image tensor to add a batch dimension\n",
    "image_tensor = tf.reshape(image_tensor, [1, image_tensor.shape[0], image_tensor.shape[1], 1])\n",
    "\n",
    "# Define a 3x3 convolution kernel\n",
    "kernel = np.array([[1, 1, 1],\n",
    "                   [1, -8, 1],\n",
    "                   [1, 1, 1]], dtype=np.float32)\n",
    "kernel = tf.constant(kernel, dtype=tf.float32)\n",
    "kernel = tf.reshape(kernel, [3, 3, 1, 1])\n",
    "\n",
    "# Apply convolution with a stride of 4\n",
    "output = tf.nn.conv2d(image_tensor, kernel, strides=[1, 4, 4, 1], padding=\"SAME\")\n",
    "\n",
    "# Remove the batch dimension from the output\n",
    "output = tf.squeeze(output)\n",
    "\n",
    "# Normalize the output to the range [0, 255]\n",
    "output = tf.clip_by_value(output, 0.0, 255.0)\n",
    "output = tf.round(output)\n",
    "output = tf.cast(output, dtype=tf.uint8)\n",
    "\n",
    "# Convert the output tensor to a NumPy array\n",
    "output_array = output.numpy()\n",
    "\n",
    "# Save the resulting image\n",
    "output_image = Image.fromarray(output_array)\n",
    "output_image.save(\"convolution_result_stride4.jpg\")  # Replace with your desired output file path\n",
    "\n",
    "# Display the output image using matplotlib\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(Image.open(\"ali.jpg\"))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Convolved Image Stride 4\")\n",
    "plt.imshow(output_image)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6553d4f",
   "metadata": {},
   "source": [
    "# Lab 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580206be",
   "metadata": {},
   "source": [
    "## Tokenization Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8760dc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"The sun is shining, and the birds are singing.\",\n",
    "    \"This is a beautiful painting of a serene landscape.\",\n",
    "    \"The traffic is unbearable during rush hour.\",\n",
    "    \"I just lost my job, and I don't know what to do.\",\n",
    "    \"She scored the winning goal in the last minute of the game.\",\n",
    "    \"The movie had a slow start, but it got better as it went on.\",\n",
    "    \"I found a wallet on the street, and I'm trying to find its owner.\",\n",
    "    \"The weather forecast predicts rain for the entire weekend.\",\n",
    "    \"I received a promotion at work today, and I'm over the moon.\",\n",
    "    \"The food at the new restaurant was terrible, and the service was slow.\",\n",
    "]\n",
    "labels = np.array([1,1,0,0,1,1,1,0,1,0])\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Initialize NLTK's stopwords and punctuations\n",
    "stop_words = set(stopwords.words('english'))\n",
    "punctuations = set(string.punctuation)\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    # Tokenization and lowercase conversion\n",
    "    words = word_tokenize(text.lower())\n",
    "\n",
    "    # Remove punctuation and stop words\n",
    "    words = [word for word in words if word not in punctuations and word not in stop_words]\n",
    "\n",
    "    return words\n",
    "\n",
    "# Preprocess the sentences\n",
    "preprocessed_sentences = [preprocess_text(sentence) for sentence in sentences]\n",
    "\n",
    "# Print the preprocessed sentences\n",
    "for i, sentence in enumerate(preprocessed_sentences):\n",
    "    print(f\"Sentence {i+1}: {sentence}\")\n",
    "    \n",
    "\n",
    "    \n",
    "preprocessed_sentences = [\" \".join(sentence) for sentence in preprocessed_sentences]\n",
    "from keras.preprocessing.text import one_hot\n",
    "# integer encoding of the documents\n",
    "my_vocab_size = 100\n",
    "encoded_sentences = [one_hot(i, my_vocab_size) for i in preprocessed_sentences]\n",
    "print(encoded_sentences)\n",
    "max = 0\n",
    "for i in encoded_sentences:\n",
    "  if len(i)>max:\n",
    "    max = len(i)\n",
    "print(max)\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "length = max\n",
    "padded_sentences = pad_sequences(encoded_sentences, maxlen=length, padding='pre')\n",
    "print(padded_sentences)\n",
    "\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "mymodel = Sequential()\n",
    "mymodel.add(Embedding(my_vocab_size, max, input_length=length))\n",
    "mymodel.add(Flatten())\n",
    "mymodel.add(Dense(1, activation='sigmoid'))\n",
    "mymodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "mymodel.fit(padded_sentences, labels, epochs=30)\n",
    "\n",
    "\n",
    "\n",
    "mysent_to_predict = ['The sun is shining, and the birds are singing',\n",
    "        'This is a beautiful painting of a serene landscape']\n",
    "preprocessed_mysent_to_predict = [preprocess_text(sentence) for sentence in mysent_to_predict]\n",
    "preprocessed_mysent_to_predict = [\" \".join(sentence) for sentence in preprocessed_mysent_to_predict]\n",
    "# integer encode the documents\n",
    "vocab_size = 100\n",
    "encoded = [one_hot(d, vocab_size) for d in preprocessed_mysent_to_predict]\n",
    "print(encoded)\n",
    "# pad documents to a max length of 5 words\n",
    "max_length = max\n",
    "mypadded = pad_sequences(encoded, maxlen=max_length, padding='pre')\n",
    "print(mypadded)\n",
    "predictions = mymodel.predict(mypadded)\n",
    "\n",
    "# Define a threshold for classification (e.g., 0.5)\n",
    "threshold = 0.5\n",
    "\n",
    "# Convert predicted probabilities to binary class labels\n",
    "predicted_classes = [1 if prediction >= threshold else 0 for prediction in predictions]\n",
    "\n",
    "# Print the predicted class labels\n",
    "print(predicted_classes)\n",
    "\n",
    "\n",
    "# evaluate the model\n",
    "modelloss, modelaccuracy = mymodel.evaluate(mypadded, pred_labels, verbose=0)\n",
    "print('Accuracy: %f' % (modelaccuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3be8511",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcaa7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define tokenized senences as training data\n",
    "tokenized_sentences = [['Hello','This','is','python','training','by','Sarim'],\n",
    "             ['Hello','This','is','Java','training','by','Sarim'],\n",
    "             ['Hello','This','is','Data Science','training','by','Unfold','Data','Science'],\n",
    "             ['Hello','This','is','programming','training','']]\n",
    "\n",
    "# training word2vec model\n",
    "from gensim.models import Word2Vec\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "mymodel = Word2Vec(tokenized_sentences, min_count=1)\n",
    "\n",
    "words = mymodel.wv.index_to_key\n",
    "print(words)\n",
    "\n",
    "print(mymodel.wv['Hello'])\n",
    "\n",
    "mymodel.wv.most_similar(\"laptop\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
